{
 "metadata": {
  "name": "",
  "signature": "sha256:c3365d508a8a846f5c620728ee0dfc30cc1c043f4565d2d84511f55e461db7d2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "# Make sure that caffe is on the python path:\n",
      "#I found it works better if you make it an absolute path\n",
      "caffe_root = \"/home/aronowb14/caffe/\"  # this file is expected to be in {caffe_root}/examples\n",
      "\n",
      "import sys\n",
      "sys.path.insert(0, caffe_root + 'python')\n",
      "\n",
      "import caffe\n",
      "\n",
      "plt.rcParams['figure.figsize'] = (10, 10)\n",
      "plt.rcParams['image.interpolation'] = 'nearest'\n",
      "plt.rcParams['image.cmap'] = 'gray'\n",
      "\n",
      "caffe.set_mode_gpu()\n",
      "\"\"\"\n",
      "#I made a new folder to put all the data in , (\"fine_tuning\"),\n",
      "#Basically you should copy all the files in the bvlc_reference_caffenet folder to your new folder\n",
      "#I'll show you how to edit the nets, and trim them and shit, it's pretty easy actually,\n",
      "#All the info is in the deploy.prototxt and train_val.prototxt\n",
      "\n",
      "\n",
      "Some shit you need:\n",
      "    in train_val.prototxt:\n",
      "    \n",
      "    write 'force_backward: true' (allows full backprop to the data layer)\n",
      "    goto 'loss' and rewrite 'bottom: softmax/whatever the default is' to 'bottom: your_output_layer'\n",
      "    \n",
      "In deploy.prototxt:\n",
      "    Cut out all the layers you're not using\n",
      "    \n",
      "\n",
      "\"\"\"\n",
      "net = caffe.Net(caffe_root + 'models/fine_tuning/deploy.prototxt',\n",
      "                caffe_root + 'models/fine_tuning/bvlc_reference_caffenet.caffemodel',\n",
      "                caffe.TEST)\n",
      "\n",
      "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
      "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
      "transformer.set_transpose('data', (2,0,1))\n",
      "transformer.set_mean('data', np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1)) # mean pixel\n",
      "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
      "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order inst"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print net.blobs.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['data', 'conv1']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def pix_mse(output, target):\n",
      "    #both are the conv4 layers of the net ['conv4'].diff\n",
      "    #print 'equal output and target?', np.array_equal(output,target)\n",
      "    if output.shape != target.shape:\n",
      "        print 'wrong shapes'\n",
      "        return False\n",
      "    \n",
      "    output = output - target\n",
      "    output = des(output)\n",
      "    return output\n",
      "\n",
      "def descend(val):\n",
      "    if (val > 0):\n",
      "        return 1.0*val\n",
      "    else: return 0.0\n",
      "    \n",
      "    \n",
      "def gram_matrix(layer_dat):\n",
      "    vectorized = np.array([filter.flatten() for filter in layer_dat[:]])\n",
      "    gram = np.zeros((vectorized.shape[0], vectorized.shape[0]))\n",
      "    #(96, 96)\n",
      "    for i in range(gram.shape[0]):\n",
      "        for j in range(gram.shape[0]):\n",
      "            gram[i][j] = vectorized[i].dot(vectorized[j]) #scalar\n",
      "    return gram\n",
      "\n",
      "def gram_der(gram_activation, gram_target, layer_name):\n",
      "    \n",
      "    feature_maps = net.blobs[layer_name].data[0]\n",
      "    n = feature_maps.shape[0] **2\n",
      "    m = feature_maps.shape[1] **4\n",
      "    factor = 1.0/(n * m) #(factor is one over the total number of neurons)\n",
      "    \n",
      "    diff = gram_activation - gram_target\n",
      "    trans = feature_maps.T\n",
      "    result = trans.dot(diff)\n",
      "    result *= factor\n",
      "    result = des(result)\n",
      "    #gradient is too fucking big!!! What up with that\n",
      "    return result\n",
      "\n",
      "def average(gen_images):\n",
      "    result = np.zeros(gen_images[0].shape) #create storage\n",
      "    for gen_image in gen_images:\n",
      "        result += gen_image\n",
      "    result = result/gen_images.shape[0] #average\n",
      "    return result\n",
      "\n",
      "def transform(diff):\n",
      "    #flip some shit, input = (96,55,55)\n",
      "    for filter in diff:\n",
      "        filter = filter.T\n",
      "    return diff\n",
      "    \n",
      "des = np.vectorize(descend)\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#batch size of one\n",
      "net.blobs['data'].reshape(1,3,227,227)\n",
      "#get the cat\n",
      "cat_dickhead = transformer.preprocess('data', caffe.io.load_image(caffe_root + 'examples/images/starry.jpg'))\n",
      "net.blobs['data'].data[...] = cat_dickhead #cat is named dickhead\n",
      "plt.imshow(transformer.deprocess('data', net.blobs['data'].data[0]), cmap = plt.cm.jet)\n",
      "\n",
      "\n",
      "#forward pass, save filter state\n",
      "net.forward()\n",
      "#make a copy of the target\n",
      "target = np.copy(net.blobs['conv1'].data[0])\n",
      "target_gram = gram_matrix(target)\n",
      "#target is the activation data\n",
      "batch_size = 2\n",
      "net.blobs['data'].reshape(batch_size,3,227,227) #batch size x\n",
      "random = transformer.preprocess('data', caffe.io.load_image(caffe_root + 'examples/images/random2.jpg'))\n",
      "net.blobs['data'].data[...] = np.copy(random)\n",
      "\n",
      "#just drawing stuff, don't worry about it\n",
      "fig = plt.figure()\n",
      "ax1 = fig.add_subplot(2,1,1)\n",
      "ax1.set_title(\"original\")\n",
      "ax1.imshow(transformer.deprocess('data', net.blobs['data'].data[0]), cmap = plt.cm.jet)\n",
      "ax2 = fig.add_subplot(1,2,1)\n",
      "ax2.set_title(\"generated\")\n",
      "\n",
      "content_learning_rate = .00001\n",
      "content_iterations = 10000\n",
      "style_learning_rate = .00001\n",
      "style_iterations = 10000\n",
      "\"\"\"\n",
      "#Gradient descent: do that shit slowly, lots of iterations, super small training rate.\n",
      "#Below is the content matching\n",
      "#Watch out for errant responses: sometimes you get a valid looking response, but it is inaccurate,\n",
      "#due to the fact that it's just matching one filter more than others\n",
      "\n",
      "\n",
      "Algorithm to determine the learning rate/iterations for gradient descent?\n",
      "Figure out the ratio between values in the gradient matrix? Try to get all the values to be in a range?\n",
      "Use the min and max values in the gradients and in the data being changed?\n",
      "\n",
      "\n",
      "for i in range(content_iterations):\n",
      "    #net propagates forward\n",
      "    net.forward()\n",
      "    #store random noise data\n",
      "    curr = net.blobs['conv1'].data[0]\n",
      "    \n",
      "    #compare random noise data with target data, store gradient\n",
      "    diff = pix_mse(curr, target)\n",
      "    #set gradient\n",
      "    net.blobs['conv1'].diff[...] = diff\n",
      "    #backpropagate\n",
      "    net.backward()\n",
      "    #get input gradient\n",
      "    input_grad = net.blobs['data'].diff[0]\n",
      "    print input_grad\n",
      "    #subtract gradient from random noise\n",
      "    net.blobs['data'].data[0] -= content_learning_rate*input_grad\n",
      "\"\"\"    \n",
      "for i in range(style_iterations):\n",
      "    #net propagates forward\n",
      "    net.forward()\n",
      "    #store random noise data\n",
      "    currs = net.blobs['conv1'].data[...] #store all the data\n",
      "    #compare random noise data with target data, store gradient\n",
      "    curr_grams = [gram_matrix(curr) for curr in currs]\n",
      "    diffs = [gram_der(curr_gram, target_gram, 'conv1') for curr_gram in curr_grams]\n",
      "    #set gradient\n",
      "    '''\n",
      "    Once you have the diffs, shape (55,55,96), how do you assign the gradients?\n",
      "    Right amount of neurons,\n",
      "    '''\n",
      "    diffs = [diff.T for diff in diffs]\n",
      "    net.blobs['conv1'].diff[...] = diffs\n",
      "    #backpropagate\n",
      "    net.backward()\n",
      "    #get input gradient\n",
      "    input_grads = net.blobs['data'].diff[...]\n",
      "    input_grad = input_grads[0]\n",
      "    #subtract gradient from random noise\n",
      "    net.blobs['data'].data[...] -= style_learning_rate*input_grad\n",
      "    if i%100 == 0:\n",
      "        print i\n",
      "print 'random picture the same?',np.array_equal(cat_dickhead, net.blobs['data'].data[0])\n",
      "ax2.imshow(transformer.deprocess('data', net.blobs['data'].data[0]), cmap = plt.cm.jet)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net.blobs['data'].reshape(300,3,227,227)\n",
      "net.blobs['data'].data[...] = cat_dickhead\n",
      "#see how it fares on larger batch sizes\n",
      "for i in range(10):\n",
      "    caffe.set_mode_cpu()\n",
      "    print 'cpu'\n",
      "    %timeit net.forward()\n",
      "    %timeit net.backward()\n",
      "    caffe.set_mode_gpu()\n",
      "    print 'gpu'\n",
      "    %timeit net.forward()\n",
      "    %timeit net.backward()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cpu\n",
        "1 loops, best of 3: 1 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.46 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gpu\n",
        "1 loops, best of 3: 690 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.26 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cpu\n",
        "1 loops, best of 3: 997 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.45 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gpu\n",
        "1 loops, best of 3: 693 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.27 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cpu\n",
        "1 loops, best of 3: 996 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.45 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gpu\n",
        "1 loops, best of 3: 692 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.26 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cpu\n",
        "1 loops, best of 3: 996 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.45 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gpu\n",
        "1 loops, best of 3: 690 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.27 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cpu\n",
        "1 loops, best of 3: 995 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.45 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gpu\n",
        "1 loops, best of 3: 692 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.26 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cpu\n",
        "1 loops, best of 3: 1.1 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.59 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gpu\n",
        "1 loops, best of 3: 692 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.26 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cpu\n",
        "1 loops, best of 3: 995 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.45 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gpu\n",
        "1 loops, best of 3: 692 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.26 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cpu\n",
        "1 loops, best of 3: 997 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.45 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gpu\n",
        "1 loops, best of 3: 692 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.26 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cpu\n",
        "1 loops, best of 3: 995 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.45 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gpu\n",
        "1 loops, best of 3: 692 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.27 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cpu\n",
        "1 loops, best of 3: 996 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.45 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gpu\n",
        "1 loops, best of 3: 690 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 3: 1.27 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\"\n",
      "Useful caffe methods:\n",
      "net.params.keys() returns the special layers i guess?\n",
      "net.blobs.keys() returns all the layers\n",
      "\n",
      "Data streams: haven't really explored this yet\n",
      "net.blobs -> stores data stream\n",
      "net.layers -> stores weight parameters \n",
      "\n",
      "\"\"\"\n",
      "a = net.blobs['data'].data[1]\n",
      "print a\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[[  6.92712152e+29   6.13729024e+29   4.56406218e+29 ...,   1.28196232e+30\n",
        "     1.45182667e+30  -8.05867307e+29]\n",
        "  [  8.40459812e+29   7.87439953e+29   6.48875369e+29 ...,   9.83647024e+26\n",
        "    -5.15194599e+28  -2.26952793e+30]\n",
        "  [  8.27913580e+29   7.55008402e+29   6.62840049e+29 ...,  -3.19681151e+30\n",
        "    -3.31166701e+30  -4.67845920e+30]\n",
        "  ..., \n",
        "  [ -5.70680324e+30  -5.13663695e+30  -5.90927837e+30 ...,  -4.28673822e+30\n",
        "    -4.31933026e+30  -5.03545439e+30]\n",
        "  [ -4.56518467e+30  -3.73129423e+30  -4.43550259e+30 ...,  -3.79083413e+30\n",
        "    -3.89535151e+30  -4.75101742e+30]\n",
        "  [ -4.60940476e+30  -4.14912831e+30  -3.93590856e+30 ...,  -3.88378783e+30\n",
        "    -4.14525915e+30  -4.84411589e+30]]\n",
        "\n",
        " [[  8.10631759e+29   1.02372942e+30   1.11709317e+30 ...,  -2.58394142e+30\n",
        "    -1.91365915e+30  -3.04041700e+30]\n",
        "  [  1.07356156e+30   1.41728585e+30   1.71988693e+30 ...,  -4.62479650e+30\n",
        "    -3.97031005e+30  -4.28602768e+30]\n",
        "  [  1.35668874e+30   1.89401290e+30   2.37439877e+30 ...,  -8.01806691e+30\n",
        "    -7.58508288e+30  -7.32178971e+30]\n",
        "  ..., \n",
        "  [ -1.33632037e+31  -1.31361589e+31  -1.24396956e+31 ...,  -8.43258702e+30\n",
        "    -7.76003862e+30  -7.44760867e+30]\n",
        "  [ -1.18418527e+31  -1.08007826e+31  -1.06048484e+31 ...,  -6.46258075e+30\n",
        "    -6.62962528e+30  -6.44514501e+30]\n",
        "  [ -1.10072164e+31  -1.00572171e+31  -9.34938680e+30 ...,  -5.21511921e+30\n",
        "    -5.35602556e+30  -5.42423738e+30]]\n",
        "\n",
        " [[ -1.31458956e+30  -1.45933380e+30  -1.43831556e+30 ...,   7.79468704e+30\n",
        "     1.07448819e+31   1.21545740e+31]\n",
        "  [ -1.66097492e+30  -2.04851966e+30  -2.02055812e+30 ...,   9.18931777e+30\n",
        "     1.14326156e+31   1.33636619e+31]\n",
        "  [ -1.78701057e+30  -2.46390370e+30  -2.65713372e+30 ...,   1.15870354e+31\n",
        "     1.21842242e+31   1.29100028e+31]\n",
        "  ..., \n",
        "  [  1.26323645e+31   1.15836915e+31   1.12404412e+31 ...,   7.43762415e+30\n",
        "     7.25085720e+30   6.72473027e+30]\n",
        "  [  1.12298485e+31   1.02735665e+31   9.79625051e+30 ...,   6.58596311e+30\n",
        "     6.07637428e+30   5.98535728e+30]\n",
        "  [  1.01528588e+31   9.04436333e+30   8.58883887e+30 ...,   5.35140806e+30\n",
        "     5.24708744e+30   5.45692069e+30]]]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conv1 = net.blobs['conv1'].data[0]\n",
      "print conv1.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(96, 55, 55)\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec = np.asarray([filter.flatten() for filter in conv1[:]])\n",
      "vec.shape\n",
      "g1 = gram_matrix(conv1)\n",
      "g2 = gram_matrix(conv1)\n",
      "gram_der(g1, g2, 'conv1').shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "(3025, 96)"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "55*55"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "3025"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = net.params['conv1']\n",
      "print pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<caffe._caffe.BlobVec object at 0x7ffa2b33e980>\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pos[0].data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(96, 3, 11, 11)\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}